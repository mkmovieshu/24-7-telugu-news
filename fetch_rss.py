import os
import logging
import time
from pymongo import MongoClient, ASCENDING
import feedparser
from datetime import datetime, timedelta, timezone

# üö® ‡∞ï‡±ä‡∞§‡±ç‡∞§‡∞ó‡∞æ ‡∞ö‡±á‡∞∞‡±ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø: Gemini API
from google import genai 
from google.genai.errors import APIError 

# ==============================================================================
# 1. ‡∞∏‡±Ü‡∞ü‡∞™‡±ç (Setup)
# ==============================================================================

# ‡∞≤‡∞æ‡∞ó‡∞ø‡∞Ç‡∞ó‡±ç ‡∞∏‡±Ü‡∞ü‡∞™‡±ç
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger('shortnews')

# RSS ‡∞´‡±Ä‡∞°‡±ç URL‡∞≤‡±Å
RSS_FEEDS = [
    "https://telugu.news18.com/commonfeeds/v1/tel/rss/andhra-pradesh.xml",
    "https://telugu.news18.com/commonfeeds/v1/tel/rss/international.xml",
    "https://telugu.news18.com/commonfeeds/v1/tel/rss/national.xml",
    "https://telugu.news18.com/commonfeeds/v1/tel/rss/telangana.xml",
    "https://www.teluguone.com/news/tonefeeds/latestnews/latestnews-25.rss",
]

# MongoDB ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç
try:
    MONGO_URI = os.getenv("MONGO_URI") 
    MONGO_DB_NAME = os.getenv("MONGO_DB_NAME", "shortnews")
    
    if not MONGO_URI:
        raise ValueError("MONGO_URI environment variable not found. Please set the MONGO_URI in your environment variables.")
    
    client = MongoClient(MONGO_URI)
    db = client[MONGO_DB_NAME]
    news_collection = db["news"]
    logger.info("MongoDB ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞Ç‡∞§‡∞Ç.")

except Exception as e:
    logger.error(f"MongoDB ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞≤‡±ã‡∞™‡∞Ç: {e}")
    # ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞≤‡±ã‡∞™‡∞Ç ‡∞â‡∞Ç‡∞ü‡±á ‡∞∏‡±ç‡∞ï‡±ç‡∞∞‡∞ø‡∞™‡±ç‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞Ü‡∞™‡∞ø‡∞µ‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
    exit(1) 

# Gemini API ‡∞∏‡±Ü‡∞ü‡∞™‡±ç
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    logger.warning("GEMINI_API_KEY environment variable not found. Summaries will be empty.")
    gemini_client = None
else:
    # üö® Gemini ‡∞ï‡±ç‡∞≤‡∞Ø‡∞ø‡∞Ç‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞∏‡±Ü‡∞ü‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
    try:
        gemini_client = genai.Client(api_key=GEMINI_API_KEY)
        logger.info("Gemini API ‡∞ï‡±ç‡∞≤‡∞Ø‡∞ø‡∞Ç‡∞ü‡±ç ‡∞∏‡±Ü‡∞ü‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø.")
    except Exception as e:
        logger.error(f"Gemini ‡∞ï‡±ç‡∞≤‡∞Ø‡∞ø‡∞Ç‡∞ü‡±ç ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç‡∞≤‡±ã ‡∞≤‡±ã‡∞™‡∞Ç: {e}")
        gemini_client = None


# ==============================================================================
# 2. ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç‡∞∏‡±ç (Functions)
# ==============================================================================

def generate_summary(text):
    """Gemini API ‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø."""
    if not gemini_client:
        return "‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞Ç ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡∞∞‡±ç ‡∞Ö‡∞Ç‡∞¶‡±Å‡∞¨‡∞æ‡∞ü‡±Å‡∞≤‡±ã ‡∞≤‡±á‡∞¶‡±Å."

    # Gemini ‡∞™‡±ç‡∞∞‡∞æ‡∞Ç‡∞™‡±ç‡∞ü‡±ç
    prompt = f"""
    ‡∞Æ‡±Ä‡∞∞‡±Å 24/7 ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞∑‡∞æ‡∞∞‡±ç‡∞ü‡±ç ‡∞®‡±ç‡∞Ø‡±Ç‡∞∏‡±ç ‡∞õ‡∞æ‡∞®‡±Ü‡∞≤‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞™‡∞®‡∞ø ‡∞ö‡±á‡∞∏‡±á AI ‡∞Ö‡∞∏‡∞ø‡∞∏‡±ç‡∞ü‡±Ü‡∞Ç‡∞ü‡±ç‚Äå‡∞ó‡∞æ ‡∞µ‡±ç‡∞Ø‡∞µ‡∞π‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.
    ‡∞ï‡∞ø‡∞Ç‡∞¶ ‡∞á‡∞ö‡±ç‡∞ö‡∞ø‡∞® ‡∞µ‡∞æ‡∞∞‡±ç‡∞§ ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞ï‡∞Ç‡∞ü‡±Ü‡∞Ç‡∞ü‡±ç‚Äå‡∞®‡±Å (content) **‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã** 30 ‡∞®‡±Å‡∞Ç‡∞°‡∞ø 50 ‡∞™‡∞¶‡∞æ‡∞≤‡∞≤‡±ã ‡∞ö‡∞¶‡∞ø‡∞µ‡±á‡∞Ç‡∞¶‡±Å‡∞ï‡±Å ‡∞∏‡±Å‡∞≤‡∞≠‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞°‡±á **‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞æ‡∞®‡±ç‡∞®‡∞ø (summary)** ‡∞Æ‡∞æ‡∞§‡±ç‡∞∞‡∞Æ‡±á ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.
    
    ‡∞µ‡∞æ‡∞∞‡±ç‡∞§ ‡∞ï‡∞Ç‡∞ü‡±Ü‡∞Ç‡∞ü‡±ç:
    ---
    {text}
    ---
    """
    
    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash', # ‡∞µ‡±á‡∞ó‡∞µ‡∞Ç‡∞§‡∞Æ‡±à‡∞®, ‡∞§‡∞ï‡±ç‡∞ï‡±Å‡∞µ ‡∞ñ‡∞∞‡±ç‡∞ö‡±Å‡∞§‡±ã ‡∞ï‡±Ç‡∞°‡∞ø‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç
            contents=prompt
        )
        return response.text.strip()
    except APIError as e:
        logger.error(f"Gemini API ‡∞≤‡±ã‡∞™‡∞Ç: {e}")
        return "‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞Ç ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã API ‡∞≤‡±ã‡∞™‡∞Ç ‡∞∏‡∞Ç‡∞≠‡∞µ‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ç‡∞¶‡∞ø."
    except Exception as e:
        logger.error(f"‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞Ç ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã ‡∞ä‡∞π‡∞ø‡∞Ç‡∞ö‡∞®‡∞ø ‡∞≤‡±ã‡∞™‡∞Ç: {e}")
        return "‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞Ç ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã ‡∞≤‡±ã‡∞™‡∞Ç."

def fetch_and_store():
    """RSS ‡∞´‡±Ä‡∞°‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞´‡±Ü‡∞ö‡±ç ‡∞ö‡±á‡∞∏‡∞ø, ‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞æ‡∞≤‡∞®‡±Å ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡±ç ‡∞ö‡±á‡∞∏‡∞ø, ‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç‚Äå‡∞≤‡±ã ‡∞∏‡±á‡∞µ‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø."""
    logger.info("RSS ‡∞´‡±Ä‡∞°‡±ç ‡∞´‡±Ü‡∞ö‡∞ø‡∞Ç‡∞ó‡±ç ‡∞™‡±ç‡∞∞‡∞æ‡∞∞‡∞Ç‡∞≠‡∞Æ‡±à‡∞Ç‡∞¶‡∞ø.")
    
    # üö® ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞Æ‡∞æ‡∞∞‡±ç‡∞™‡±Å 1: ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞∏‡∞æ‡∞∞‡∞ø ‡∞™‡∞æ‡∞§ ‡∞µ‡∞æ‡∞∞‡±ç‡∞§‡∞≤‡∞®‡±Å ‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞ø‡∞ó‡∞æ ‡∞§‡±ä‡∞≤‡∞ó‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø
    # ‡∞¶‡±Ä‡∞®‡∞ø ‡∞µ‡∞≤‡∞® ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±Å‡∞®‡±Å‡∞™‡∞ü‡∞ø ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø‡∞®‡±Å ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞æ‡∞∞‡±Å.
    try:
        news_collection.delete_many({})
        logger.info("‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞™‡∞æ‡∞§ ‡∞µ‡∞æ‡∞∞‡±ç‡∞§‡∞≤‡±Å ‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞Ç‡∞§‡∞Ç‡∞ó‡∞æ ‡∞§‡±ä‡∞≤‡∞ó‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡±ç‡∞°‡∞æ‡∞Ø‡∞ø.")
    except Exception as e:
        logger.error(f"‡∞™‡∞æ‡∞§ ‡∞µ‡∞æ‡∞∞‡±ç‡∞§‡∞≤‡∞®‡±Å ‡∞§‡±ä‡∞≤‡∞ó‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç‡∞≤‡±ã ‡∞≤‡±ã‡∞™‡∞Ç: {e}")

    # üö® ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞Æ‡∞æ‡∞∞‡±ç‡∞™‡±Å 2: 12 ‡∞ó‡∞Ç‡∞ü‡∞≤ ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§ ‡∞Ü‡∞ü‡±ã-‡∞°‡∞ø‡∞≤‡±Ä‡∞ü‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç TTL ‡∞á‡∞Ç‡∞°‡±Ü‡∞ï‡±ç‡∞∏‡±ç‚Äå‡∞®‡±Å ‡∞∏‡±Ü‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
    try:
        # expireAfterSeconds=43200 (12 ‡∞ó‡∞Ç‡∞ü‡∞≤‡±Å = 12 * 60 * 60 ‡∞∏‡±Ü‡∞ï‡∞®‡±ç‡∞≤‡±Å)
        news_collection.create_index(
            [("created_at", ASCENDING)], 
            expireAfterSeconds=43200, 
            background=True
        )
        logger.info("TTL ‡∞á‡∞Ç‡∞°‡±Ü‡∞ï‡±ç‡∞∏‡±ç (12 ‡∞ó‡∞Ç‡∞ü‡∞≤‡±Å) ‡∞µ‡∞ø‡∞ú‡∞Ø‡∞µ‡∞Ç‡∞§‡∞Ç‡∞ó‡∞æ ‡∞∏‡±Ü‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø.")
    except Exception as e:
        logger.error(f"TTL ‡∞á‡∞Ç‡∞°‡±Ü‡∞ï‡±ç‡∞∏‡±ç ‡∞∏‡±Ü‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã ‡∞≤‡±ã‡∞™‡∞Ç: {e}")


    for feed_url in RSS_FEEDS:
        try:
            feed = feedparser.parse(feed_url)
            
            for entry in feed.entries:
                # ‡∞§‡±á‡∞¶‡±Ä‡∞®‡∞ø ‡∞™‡∞æ‡∞∞‡±ç‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
                published_date = datetime.utcnow() # ‡∞°‡∞ø‡∞´‡∞æ‡∞≤‡±ç‡∞ü‡±ç: ‡∞á‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    published_date = datetime.fromtimestamp(
                        time.mktime(entry.published_parsed), 
                        tz=timezone.utc
                    ).replace(tzinfo=None)

                # üö® ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞Æ‡∞æ‡∞∞‡±ç‡∞™‡±Å 3: Gemini API ‡∞®‡∞ø ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
                full_text = getattr(entry, 'description', getattr(entry, 'summary', entry.title))
                
                # ‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ú‡∞®‡∞∞‡±á‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø
                summary_text = generate_summary(full_text)

                news_item = {
                    "title": entry.title,
                    "summary": summary_text, # ‚úÖ ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞∏‡∞æ‡∞∞‡∞æ‡∞Ç‡∞∂‡∞Ç ‡∞ú‡∞§ ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø
                    "link": entry.link,
                    "source": feed_url,
                    "published": published_date, 
                    "created_at": datetime.utcnow(), # TTL ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞à ‡∞´‡±Ä‡∞≤‡±ç‡∞°‡±ç ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç
                    "likes": 0,
                    "dislikes": 0
                }
                
                # ‡∞°‡±Ç‡∞™‡±ç‡∞≤‡∞ø‡∞ï‡±á‡∞ü‡±ç‚Äå‡∞≤‡∞®‡±Å ‡∞®‡∞ø‡∞µ‡∞æ‡∞∞‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø
                # (‡∞Æ‡±á‡∞Æ‡±Å ‡∞á‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞ï‡±á ‡∞ï‡∞≤‡±Ü‡∞ï‡±ç‡∞∑‡∞®‡±ç‚Äå‡∞®‡±Å ‡∞ï‡±ç‡∞≤‡±Ä‡∞®‡±ç ‡∞ö‡±á‡∞∏‡∞æ‡∞Æ‡±Å, ‡∞ï‡∞æ‡∞¨‡∞ü‡±ç‡∞ü‡∞ø ‡∞à ‡∞°‡±Ç‡∞™‡±ç‡∞≤‡∞ø‡∞ï‡±á‡∞ü‡±ç ‡∞ö‡±Ü‡∞ï‡±ç ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞Ö‡∞®‡∞µ‡∞∏‡∞∞‡∞Ç, ‡∞ï‡∞æ‡∞®‡±Ä ‡∞â‡∞Ç‡∞°‡∞ü‡∞Ç ‡∞Æ‡∞Ç‡∞ö‡∞ø‡∞¶‡∞ø)
                try:
                    news_collection.insert_one(news_item)
                    logger.info(f"‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞®‡±ç‡∞Ø‡±Ç‡∞∏‡±ç ‡∞á‡∞®‡±ç‡∞∏‡∞∞‡±ç‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø: {entry.title[:50]}...")
                    
                except Exception as e:
                    if "duplicate key error" in str(e):
                        logger.debug(f"‡∞®‡±ç‡∞Ø‡±Ç‡∞∏‡±ç ‡∞á‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞ï‡±á ‡∞â‡∞Ç‡∞¶‡∞ø, ‡∞∏‡±ç‡∞ï‡∞ø‡∞™‡±ç ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø: {entry.title[:50]}...")
                    else:
                        logger.error(f"‡∞°‡±á‡∞ü‡∞æ‡∞¨‡±á‡∞∏‡±ç ‡∞≤‡±ã‡∞™‡∞Ç: {e}")
                        
            logger.info(f"Successfully fetched and processed feed: {feed_url}")

        except Exception as e:
            logger.error(f"Error fetching/processing feed {feed_url}: {e}")

    logger.info("RSS ‡∞´‡±Ä‡∞°‡±ç ‡∞´‡±Ü‡∞ö‡∞ø‡∞Ç‡∞ó‡±ç ‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞Ø‡∞ø‡∞Ç‡∞¶‡∞ø.")

# ==============================================================================
# 3. ‡∞∏‡±ç‡∞ï‡±ç‡∞∞‡∞ø‡∞™‡±ç‡∞ü‡±ç ‡∞é‡∞ó‡±ç‡∞ú‡∞ø‡∞ï‡±ç‡∞Ø‡±Ç‡∞∑‡∞®‡±ç
# ==============================================================================

if __name__ == "__main__":
    fetch_and_store()
    
